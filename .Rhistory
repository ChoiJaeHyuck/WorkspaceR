install.packages( "ggiraphExtra" )   # 단계구분도 작성을 위한 패키지
install.packages( "maps" )           # R에 내장된 미국 주별 위/경도 데이터
install.packages( "mapproj" )        # 위도( latitude ) / 경도( longitude ) 표시
library( tibble )                  # dplyr 패키지 설치시 자동 설치, 행을 변수로 변환 함수
library( ggiraphExtra )
library( maps )
library( mapproj )
library( ggplot2 )
ggChoropleth( data = crime,                    # 지도에 표시
aes( fill = Murder,              # 색깔로 표현할 변수
map_id = state ),                # 지역 기준 변수
map = states_map,                # 지도 데이터
interactive =  T )               # 지도에 마우스 갖다 대면 정보가 뜸
crime <- rownames_to_column( USArrests, var = "state" )
crime$state <- tolower( crime$state )
dim( crime )
str( crime )
# map 패키지의 미국 주별 위/경도를 나타내는 state 데이터를 ggplot2의 map_data()를 이용하여 data frame 생성
states_map <- map_data( 'state' )
str( states_map )
# 단계 구분도 작성
ggChoropleth( data = crime,                    # 지도에 표시
aes( fill = Murder,              # 색깔로 표현할 변수
map_id = state ),                # 지역 기준 변수
map = states_map,                # 지도 데이터
interactive =  T )
install.packages( "devtools" ) # R용 패키지 개발용 함수 모음
devtools::install_github( "cardiomoon/kormaps2014" )
library( kormaps2014 )
library( dplyr )
str( changeCode( korpop1 ) )
korpop1 <- korpop1 %>%
rename( pop = 총인구_명,
name = 행정구역별_읍면동 )
str( changeCode( kormap1 ) )
korpop1$name <- iconv( korpop1$name, "UTF-8", "CP949" )
ggChoropleth( data = korpop1,
aes( fill = pop,
map_id = code,
tooltip = name ),
map = kormap1,
interactive = T )
ggChoropleth( data = korpop1,
aes( fill = pop,
map_id = code,
tooltip = name ),
map = kormap1,
interactive = T )
ggChoropleth( data = korpop1,
aes( fill = pop,
map_id = code,
tooltip = name ),
map = kormap1,
interactive = T )
ggChoropleth( korpop2, kormap2, fillvar = "남자_명" )
install.packages( "memories" )
install.packages( "KoNLP" )
install.packages( "KoNLP" )
install.packages( "multilinguer" )
install_jdk()
Sys.setenv( JAVA_HOME = "C:\\Java\\jdk1.8.0_251" )
install.packages( "wordcloud" )
install.packages( "wordcloud2" )
install.packages( "RColorBrewer" )
library( wordcloud )
library( wordcloud2 )
library( RColorBrewer )
library( dplyr )
library( ggplot2 )
install.packages( "ggiraphExtra" )   # 단계구분도 작성을 위한 패키지
install.packages( "maps" )           # R에 내장된 미국 주별 위/경도 데이터
install.packages( "mapproj" )        # 위도( latitude ) / 경도( longitude ) 표시
library( tibble )                  # dplyr 패키지 설치시 자동 설치, 행을 변수로 변환 함수
library( ggiraphExtra )
library( maps )
library( mapproj )
library( ggplot2 )
dim( USArrests )
str( USArrests )
head( USArrests )
crime <- rownames_to_column( USArrests, var = "state" )
crime$state <- tolower( crime$state )
dim( crime )
str( crime )
states_map <- map_data( 'state' )
str( states_map )
ggChoropleth( data = crime,                    # 지도에 표시
aes( fill = Murder,              # 색깔로 표현할 변수
map_id = state ),                # 지역 기준 변수
map = states_map,                # 지도 데이터
interactive =  T )
ggChoropleth( data = crime,                    # 지도에 표시
aes( fill = Murder,              # 색깔로 표현할 변수
map_id = state ),                # 지역 기준 변수
map = states_map,                # 지도 데이터
interactive =  T )               # 지도에 마우스 갖다 대면 정보가 뜸
install.packages( "devtools" ) # R용 패키지 개발용 함수 모음
devtools::install_github( "cardiomoon/kormaps2014" )
library( kormaps2014 )
library( dplyr )
str( changeCode( korpop1 ) )
korpop1 <- korpop1 %>%
rename( pop = 총인구_명,
name = 행정구역별_읍면동 )
str( changeCode( kormap1 ) )
korpop1$name <- iconv( korpop1$name, "UTF-8", "CP949" )
ggChoropleth( data = korpop1,
aes( fill = pop,
map_id = code,
tooltip = name ),
map = kormap1,
interactive = T )
ggChoropleth( korpop2, kormap2, fillvar = "남자_명" )
install.packages( "memories" )
install.packages( "memories" )
install.packages( "KoNLP" )
install.packages( "multilinguer" )
library( multilinguer )
install_jdk()
install.packages( "remotes" )
install.packages("remotes")
remotes::install_github( "haven-jeon/KoNLP", upgrade = "never",
INSTALL_opts = c( "--no-multiarch" ) )
library( KoNLP )     # R용 한글 자연어 처리 패키지
useNIADic()          # 사용자 사전 설정
Sys.setenv( JAVA_HOME = "C:\\Java\\jdk1.8.0_251" )
install.packages( "wordcloud" )
install.packages( "wordcloud2" )
install.packages( "RColorBrewer" )
library( wordcloud )
library( wordcloud2 )
library( RColorBrewer )
library( dplyr )
library( ggplot2 )
setwd( "C:\\Users\\USER\\Documents\\GitHub\\WorkspaceR" )
text <- readLines( 'mis_document.txt', encoding = 'UTF-8' )   # 이렇게 했는데 한글이 깨지면, encoding = 'UTF-8'부분 빼기
text
buildDictionary( ext_dic = 'woorimalsam' )
pal2 <- brewer.pal( 8, 'Dark2' )                              # 색상 팔레트 생성
noun <-  sapply( text, extractNoun, USE.NAMES = F )           # 명사 추출
noun
noun2 <- unlist( noun )
wordcount <- table( noun2 )
sort.noun <- sort( wordcount, decreasing = T)[ 1:10 ]
sort.noun                                                       # 가장 많은 빈도수는 공백임
sort.noun <- sort.noun[-1]
barplot( sort.noun, names.arg = names( sort.noun ),
col = 'steelblue', main = '빈도수 높은 단어',
ylab = '단어 빈도수')
pal3 <- brewer.pal( 9, 'Blues' )[ 5:9 ]                   # 색상 팔레트 생성
wordcloud( names( wordcount ),                            # 단어
freq = wordcount,                              # 단어 빈도
main.freq = 3,                                 # 단어 폰트 크기(최대,최소)
random.order = F,                              # 단어 최소 빈도
rot.per = .1,                                  # 90도 회전 단어 비율
colors = pal3 )
buildDictionary( ext_dic = 'woorimalsam',
user_dic = data.frame( '정치', 'ncn' ),
replace_usr_dic = T )
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun2 <- unlist( noun2 )
noun2 <- noun2[ nchar( noun2 ) > 1 ]
noun2 <- gsub( '하지','', noun2 )
noun2 <- gsub( '때문','', noun2 )
wordcount <- table( noun2 )
wordcloud( names( wordcount ), freq = wordcount,
scale = c( 6, 0.7 ), main.freq = 3,
random.order = F, rot.per = .1, colors = pal3 )
wordcloud2( wordcount, color = 'random-light',
backgroundColor = 'black' )
wordcloud2( wordcount, fontFamily = '맑은 고딕',
size = 1.2, color = 'random-light',
backgroundColor = 'black',
shape = 'star')
wordcloud2( demoFreq, size = 1.6,
color = rep_len( c('red', 'blue' ),
nrow( wordcount ) ) )
wordcloud2( wordcount, size = 1.6,
color = rep_len( c('red', 'blue' ),
nrow( wordcount ) ) )
# 일정 방향 정렬
wordcloud2( wordcount,
minRotation = -pi / 6,
maxRotation = -pi / 6,
rotateRatio = 1 )
devtools::install_github( "cardiomoon/kormaps2014" )
install.packages( "ggiraphExtra" )   # 단계구분도 작성을 위한 패키지
install.packages( "maps" )           # R에 내장된 미국 주별 위/경도 데이터
install.packages( "mapproj" )        # 위도( latitude ) / 경도( longitude ) 표시
library( tibble )                  # dplyr 패키지 설치시 자동 설치, 행을 변수로 변환 함수
library( ggiraphExtra )
library( maps )
library( mapproj )
library( ggplot2 )
dim( USArrests )
str( USArrests )
head( USArrests )
# tibble 패키지 rownames_to_colnum()을 이용하여 data( 행 )를 변수( 열 )로 변경
crime <- rownames_to_column( USArrests, var = "state" )
crime$state <- tolower( crime$state )
dim( crime )
str( crime )
# map 패키지의 미국 주별 위/경도를 나타내는 state 데이터를 ggplot2의 map_data()를 이용하여 data frame 생성
states_map <- map_data( 'state' )
str( states_map )
# 단계 구분도 작성
ggChoropleth( data = crime,                    # 지도에 표시
aes( fill = Murder,              # 색깔로 표현할 변수
map_id = state ),                # 지역 기준 변수
map = states_map,                # 지도 데이터
interactive =  T )               # 지도에 마우스 갖다 대면 정보가 뜸
# https://github.com/cardiomoon/kormaps2014
# 대한민국 지도 데이터를 이용한 단계 구분도
install.packages( "devtools" ) # R용 패키지 개발용 함수 모음
# R공식 저장소( CRAN )에 없는 경우 원하는 패키지 설치 방법
devtools::install_github( "cardiomoon/kormaps2014" )
library( kormaps2014 )
library( dplyr )
# kormaps2014 지도 데이터
# kormap1 : 한국 행정 지도( 시도별 )
# kormap2 : 한국 행정 지도( 시군구별 )
# kormap3 : 한국 행정 지도( 읍면동별 )
# kormaps2014 내장 dataset
# korpop1 : 2015년 인구 센서스 데이터( 시도별 )
# korpop2 : 2015년 인구 센서스 데이터( 시군구별 )
# korpop3 : 2015년 인구 센서스 데이터( 읍면동별 )
# changeCode() : 인코딩을 cp949로 변환, 원래 kormap1에 UTF-8로 인코딩 되어 있으나, 윈도우에서는 한글 깨짐 발생
str( changeCode( korpop1 ) )
# 한글 변수명 변경
korpop1 <- korpop1 %>%
rename( pop = 총인구_명,
name = 행정구역별_읍면동 )
str( changeCode( kormap1 ) )
korpop1$name <- iconv( korpop1$name, "UTF-8", "CP949" )
ggChoropleth( data = korpop1,
aes( fill = pop,
map_id = code,
tooltip = name ),
map = kormap1,
interactive = T )
ggChoropleth( korpop2, kormap2, fillvar = "남자_명" )
# 2.2 텍스트 마이닝( word cloud )
install.packages( "memories" )
install.packages( "KoNLP" )
# KoNLP : Korean Natural Language Processing ( 한글 자연어 처리 )
install.packages( "multilinguer" )
library( multilinguer )
install_jdk()
# KoNLP 패키지 설치
install.packages( "remotes" )
remotes::install_github( "haven-jeon/KoNLP", upgrade = "never",
INSTALL_opts = c( "--no-multiarch" ) )
library( KoNLP )     # R용 한글 자연어 처리 패키지
install.packages("remotes")
remotes::install_github( "haven-jeon/KoNLP", upgrade = "never",
INSTALL_opts = c( "--no-multiarch" ) )
library( KoNLP )     # R용 한글 자연어 처리 패키지
useNIADic()          # 사용자 사전 설정
# Data Mining : 대규모로 저장된 데이터안에서 체계적이고 자동적으로 통계적 규칙이나 패턴을
#               찾아내는 것을 말하며 KDD( Knowledg-discovery in databases, 데이터베이스 속의 지식 발견 )
# Text Mining : 비정형 데이터 마이니의 유형중 하나 비정형 / 반정형 데이터에 대하여 자연어 처리 기술과
#               문서 처리 기술을 적용하여 유용한 정보를 추출, 가공하는 목적으로 하는 기술
# Word Cloud : 텍스트 데이터를 분석하는 대표기술, 대상 데이터에서 단어( 주로 명사 )르 추출하고 단어들의
#   (BoW)      출현 빈도수를 계산하여 시각화하는 도구. 출현 빈도수가 높은 단어는 그마늠 중요하거나 관심도가 높다는
# Bag of Word  것을 의미. Word Cloud에서는 출현 빈도수가 높을수록 큰 글씨로 표현
# 한글의 형태소 분석 하는것 : KoNLP
# 한글 Word Cloud 절차
# 1. Java 실행 환경 구축( JRE, Java Run-time Environment )
# 2. KoNLP 패키지 설치 / Load
# 3. 사용자 사전 설정
# 4. 자료 수집( Text 자료 )
# 4.1 text file 형태로 수집                 : 메모장으로 읽을 수 있으면 text file
# 4.2 web scraping을 이용한 수집
# 5. 명사 추출
# 6. 추출한 명사의 빈도수 계산                   : table 함수
# 7. 빈도수순으로 Sort( Descending )
# 8. 한글 Word Cloud 표현
# R에서 한글 Word Cloud를 이용하기 위해서는 Java 실행환경( JRE )필요
Sys.setenv( JAVA_HOME = "C:\\Java\\jdk1.8.0_251" )
install.packages( "wordcloud" )
install.packages( "wordcloud2" )
install.packages( "RColorBrewer" )
library( wordcloud )
library( wordcloud2 )
library( RColorBrewer )
library( dplyr )
library( ggplot2 )
# notepad ++ : 텍스트 파일 편집기능 다운
# 4. 자료 수집( Text 자료 )
setwd( "C:\\Workspace\\WorkspaceR" )
text <- readLines( 'mis_document.txt', encoding = 'UTF-8' )   # 이렇게 했는데 한글이 깨지면, encoding = 'UTF-8'부분 빼기
text
# 사용자 한글 사전 '우리말씀' 로딩
buildDictionary( ext_dic = 'woorimalsam' )
pal2 <- brewer.pal( 8, 'Dark2' )                              # 색상 팔레트 생성
noun <-  sapply( text, extractNoun, USE.NAMES = F )           # 명사 추출
noun
# 6. 추출한 명사의 빈도수 계산
noun2 <- unlist( noun )
wordcount <- table( noun2 )
# 7. 빈도수순으로 Sort( Descending )
sort.noun <- sort( wordcount, decreasing = T)[ 1:10 ]
sort.noun                                                       # 가장 많은 빈도수는 공백임
sort.noun <- sort.noun[-1]
barplot( sort.noun, names.arg = names( sort.noun ),
col = 'steelblue', main = '빈도수 높은 단어',
ylab = '단어 빈도수')
# 8. 한글 Word Cloud 작성
pal3 <- brewer.pal( 9, 'Blues' )[ 5:9 ]                   # 색상 팔레트 생성
wordcloud( names( wordcount ),                            # 단어
freq = wordcount,                              # 단어 빈도
main.freq = 3,                                 # 단어 폰트 크기(최대,최소)
random.order = F,                              # 단어 최소 빈도
rot.per = .1,                                  # 90도 회전 단어 비율
colors = pal3 )                                # 단어색
# 한글 Word Cloud를 위한 전처리
# 1. 불필요한 단어 삭제
# 2. 생략된 단어를 사전에 등재
buildDictionary( ext_dic = 'woorimalsam',
user_dic = data.frame( '정치', 'ncn' ),
replace_usr_dic = T )
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun2 <- unlist( noun2 )
# 1. 불필요한 단어 삭제
noun2 <- noun2[ nchar( noun2 ) > 1 ]
noun2 <- gsub( '하지','', noun2 )
noun2 <- gsub( '때문','', noun2 )
wordcount <- table( noun2 )
wordcloud( names( wordcount ), freq = wordcount,
scale = c( 6, 0.7 ), main.freq = 3,
random.order = F, rot.per = .1, colors = pal3 )
wordcloud2( wordcount, color = 'random-light',
backgroundColor = 'black' )
# 모양 변경
wordcloud2( wordcount, fontFamily = '맑은 고딕',
size = 1.2, color = 'random-light',
backgroundColor = 'black',
shape = 'star')
# 색상 변경
wordcloud2( demoFreq, size = 1.6,
color = rep_len( c('red', 'blue' ),
nrow( wordcount ) ) )
wordcloud2( wordcount, size = 1.6,
color = rep_len( c('red', 'blue' ),
nrow( wordcount ) ) )
# 일정 방향 정렬
wordcloud2( wordcount,
minRotation = -pi / 6,
maxRotation = -pi / 6,
rotateRatio = 1 )
# 셋 이상의 변수에 대하여 산점도 표현( 3차원 이상을 2차원으로 축소한다 )
#
# R에서는 t-SNE를 활용한 차원 축소 패키지 제공
install.packages( "Rtsne" )
library( Rtsne )
library( ggplot2 )
ds <- iris[,-5]
dup <- which( duplicated( ds ) )          # 중복 데이터 확인
dup
ds <- ds[ -dup, ]
ds.y <- iris$Species[ -dup ]              # 중복 데이터 품종 제거
# 차원 축소
tsne <- Rtsne( ds,                        # 차원 축소 대상 data frame
dims = 2,                  # 축소할 차원, 보통 2 or 3
perplexity = 10 )          # 차원 축소 과정에서 데이터를 샘플링하는 샘플수
# ( 대상 데이터 행의수 ) / 3 보다 작은수
tsne
# 차원 축소 결과 시각화
df.tsne <- data.frame( tsne$Y )
head( df.tsne )
ggplot( df.tsne, aes( x = X1, y = X2, color = ds.y ) ) +# 데이터 소실이 있기 때문에 할때 마다 다르게 나옴
geom_point( size = 2 )
# 3차원 산점도를 표현하기 위해 rgl, car 패키지 설치
install.packages( c( "rgl", "car" ) )
library( car )
library( rgl )            # 3D 시각화 패키지
library( mgcv )
library( car )
library( rgl )            # 3D 시각화 패키지
library( mgcv )
tsne <- Rtsne( ds, dims = 3, perplexity = 10 )
df.tsne <- data.frame( tsne$Y )
head( df.tsne )
scatter3d( x = df.tsne$X1, y = df.tsne$X2, z = df.tsne$X3 )
points <- as.integer( ds.y )
scatter3d( x = df.tsne$X1,  y = df.tsne$X2, z = df.tsne$X3,
point.col = color[ points ],
surface = FALSE )
points <- as.integer( ds.y )
scatter3d( x = df.tsne$X1,  y = df.tsne$X2, z = df.tsne$X3,
point.col = color[ points ],
surface = FALSE )
points <- as.integer( ds.y )
color <- c( 'red','green','blue' )
scatter3d( x = df.tsne$X1,  y = df.tsne$X2, z = df.tsne$X3,
point.col = color[ points ],
surface = FALSE )
str( cars )
head( cars )
plot( dist~speed, data = cars )
# 회귀모델 구하기
# 종속(반응)변수~독립(설명)변수 순으로 지정
model <- lm( dist~speed , cars )
model
abline( model )
coef( model )               # 매개변수( 계수 ) - W, b값
coef( model )[ 1 ]          # b값
coef( model )[ 2 ]
b <- coef( model )[ 1 ]
W <- coef( model )[ 2 ]
speed <- 21.5
dist <- W * speed + b
dist
df <- data.frame( speed = c( 21.5, 25.0, 25.5,
26.0, 26.5, 27.5,
28.0 ) )
predict( model, df )                                       # 예측 수행 함수
plot( df$speed, predict( model, df ),
col = 'red', cex = 2, pch = 20 )
abline( model )
str( cars )
speed <- cars[,1]
pred <- W * speed + b
pred
compare <- data.frame( pred, cars[,2],
pred - cars[,2] )
compare
colnames( compare ) <- c( '예상', '실제', '오차' )
head( fitted( model ), 3 )                                 # 예측
head( residuals( model ), 3 )                              # 추정된 값과의 차이이
head( compare, 3 )
fitted( model )                                  # 훈련데이터에 있는 샘플에 대한 예측값
residuals( model )                               # 잔차 : 회귀식으로 추정된 값과의 차이
deviance( model ) / length( cars$speed )
summary( model )
str( women )
head( women )
model_w <- lm( weight~height, women )
model_w
summary( model )
summary( model_w )
state.x77
str(state.x77)
head(state.x77)
plot( Illiteracy~Murder, data = state.x77 )
# 종속(반응)변수~독립(설명)변수 순으로 지정
model <- lm( Murder~Illiteracy , state.x77 )
# 종속(반응)변수~독립(설명)변수 순으로 지정
model <- lm( Murder~Illiteracy , state.x77 )
# 종속(반응)변수~독립(설명)변수 순으로 지정
model <- lm( Murder~Illiteracy, state.x77 )
# 종속(반응)변수~독립(설명)변수 순으로 지정
model <- lm( Murder~Illiteracy, state.x77 )
# 종속(반응)변수~독립(설명)변수 순으로 지정
model <- lm( Illiteracy~Murder, state.x77 )
model
str(state.x77)
class(state.x77)
S <- data.frame(state.x77)
str(S)
head(S)
plot( Illiteracy~Murder, data = S )
plot( Illiteracy~Murder, data = S )
# 종속(반응)변수~독립(설명)변수 순으로 지정
model <- lm( Murder~Illiteracy, S )
model
abline( S )
abline( model )
abline( model )
# 종속(반응)변수~독립(설명)변수 순으로 지정
model <- lm( Murder~Illiteracy, S )
model
abline( model )
)
coef( model )               # 매개변수( 계수 ) - W, b값
coef( model )[ 1 ]          # b값
coef( model )[ 2 ]          # W값
plot( Murder~Illiteracy, data = S )
# 종속(반응)변수~독립(설명)변수 순으로 지정
model <- lm( Murder~Illiteracy, S )
model
abline( model )
coef( model )               # 매개변수( 계수 ) - W, b값
coef( model )[ 1 ]          # b값
coef( model )[ 2 ]          # W값
model2 <- data.frame( Illiteracy = c(0.5, 1.0, 1,5 ) )
predict( mode1, model2 )
predict( model, model2 )
class(trees)
plot( Volume~Girth, trees )
treemodel <- lm( Volume~Girth, trees )
treemodel
abline( treemodel )
coef( treemodel )
coef( treemodel )
coef( treemodel )[1]
coef( treemodel )[2]
treemodel2 <- data.frame( Volume = c(8.5, 9.0, 9.5 ) )
predict( treemodel, treemodel2 )
treemodel2 <- data.frame( Volume = c(8.5, 9.0, 9.5 ) )
predict( treemodel, treemodel2 )
treemodel <- lm( Volume~Girth, trees )
treemodel
treemodel2 <- data.frame( Girth = c(8.5, 9.0, 9.5 ) )
predict( treemodel, treemodel2 )
class(pressure)
plot( pressure~temperature, pressure )
premodel <- lm( pressure~temperature, pressure )
premodel
abline( premodel )
premodel2 <- data.frame( temperature = c(65, 95, 155 ) )
predict( premodel, premodel2 )
